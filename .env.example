# ================================================================================
# PQC Inspector Environment Configuration
# ================================================================================
# Copy this file to .env and fill in your actual values
# WARNING: Never commit .env file with real credentials to version control!

# --- Project Settings ---
PROJECT_NAME=PQC Inspector
API_V1_STR=/api/v1
SERVER_HOST=127.0.0.1
SERVER_PORT=8000

# --- External API Settings ---
EXTERNAL_API_BASE_URL=https://jsonplaceholder.typicode.com
EXTERNAL_API_KEY=test-api-key
EXTERNAL_API_TIMEOUT=30

# --- Application Settings ---
LOG_LEVEL=INFO

# --- AI Model API Keys ---
# OpenAI API Key (for GPT models)
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-proj-your-openai-api-key-here

# Google AI API Key (for Gemini models)
# Get your key from: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=your-google-api-key-here

# --- Model Configuration ---
# Current Configuration (Cloud-based models)
# Orchestrator: File classification and result validation
ORCHESTRATOR_MODEL=gpt-4-turbo

# Source Code Agent: Code analysis
SOURCE_CODE_MODEL=gemini-2.0-flash-exp

# Binary Agent: Assembly/binary analysis
BINARY_MODEL=gemini-2.0-flash-exp

# Log/Config Agent: Log and configuration file analysis
LOG_CONF_MODEL=gemini-2.0-flash-exp

# Alternative Configuration - Llama3:8b (Local Ollama)
# Uncomment below and comment above to use llama3:8b for all models
# Requires Ollama to be installed and running: https://ollama.ai
# ORCHESTRATOR_MODEL=llama3:8b
# SOURCE_CODE_MODEL=llama3:8b
# BINARY_MODEL=llama3:8b
# LOG_CONF_MODEL=llama3:8b

# --- Legacy/Backup Settings ---
# Ollama (local LLM server - optional)
OLLAMA_BASE_URL=http://localhost:11434
