# File: pqc_inspector_server/services/document_ingestion.py
# ğŸ“š ë¬¸ì„œë¥¼ RAG ì‹œìŠ¤í…œì— ìˆ˜ì§‘í•˜ëŠ” íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.

import asyncio
import os
from typing import List, Dict, Any, Optional
from pathlib import Path
from datetime import datetime

from .document_processor import DocumentProcessor, get_document_processor
from .knowledge_manager import KnowledgeManagerFactory
from .embedding_service import get_embedding_service

class DocumentIngestionPipeline:
    def __init__(self):
        self.processor = get_document_processor()
        self.embedding_service = get_embedding_service()
        self.supported_agents = ["source_code", "assembly_binary", "logs_config"]

    async def ingest_single_document(
        self,
        file_path: str,
        agent_type: str = "auto",
        source_name: Optional[str] = None,
        confidence: float = 0.9
    ) -> Dict[str, Any]:
        """
        ë‹¨ì¼ ë¬¸ì„œë¥¼ RAG ì‹œìŠ¤í…œì— ìˆ˜ì§‘í•©ë‹ˆë‹¤.
        """
        try:
            print(f"ğŸ“š ë¬¸ì„œ ìˆ˜ì§‘ ì‹œì‘: {file_path}")

            # 1. ë¬¸ì„œ ì²˜ë¦¬
            processed_doc = await self.processor.process_document(file_path, agent_type)

            # 2. ì†ŒìŠ¤ëª… ì„¤ì •
            if not source_name:
                source_name = f"document_{Path(file_path).stem}"

            # 3. ì—ì´ì „íŠ¸ íƒ€ì… ê²€ì¦
            final_agent_type = processed_doc["agent_type"]
            if final_agent_type not in self.supported_agents:
                final_agent_type = "source_code"  # ê¸°ë³¸ê°’

            # 4. ì§€ì‹ ë§¤ë‹ˆì € ê°€ì ¸ì˜¤ê¸°
            knowledge_manager = await KnowledgeManagerFactory.get_manager(final_agent_type)

            # 5. ì²­í¬ë³„ë¡œ ì„ë² ë”© ìƒì„± ë° ì €ì¥
            success_count = 0
            total_chunks = len(processed_doc["chunks"])

            print(f"ğŸ”„ {total_chunks}ê°œ ì²­í¬ë¥¼ {final_agent_type} ì—ì´ì „íŠ¸ì— ì¶”ê°€ ì¤‘...")

            for chunk in processed_doc["chunks"]:
                try:
                    # ë©”íƒ€ë°ì´í„° ìƒì„±
                    metadata = self._create_chunk_metadata(
                        chunk, processed_doc["file_info"], source_name, confidence
                    )

                    # ì§€ì‹ ë² ì´ìŠ¤ì— ì¶”ê°€
                    success = await knowledge_manager.add_new_knowledge(
                        content=chunk["content"],
                        knowledge_type="document_chunk",
                        category=f"doc_{Path(file_path).stem}",
                        confidence=confidence,
                        source=source_name
                    )

                    if success:
                        success_count += 1
                    else:
                        print(f"âš ï¸ ì²­í¬ {chunk['index']} ì¶”ê°€ ì‹¤íŒ¨")

                except Exception as e:
                    print(f"âŒ ì²­í¬ {chunk['index']} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

            # 6. ê²°ê³¼ ë°˜í™˜
            result = {
                "success": success_count > 0,
                "file_path": file_path,
                "agent_type": final_agent_type,
                "total_chunks": total_chunks,
                "success_chunks": success_count,
                "failed_chunks": total_chunks - success_count,
                "source_name": source_name,
                "document_info": processed_doc["file_info"],
                "ingestion_time": datetime.now().isoformat()
            }

            if success_count > 0:
                print(f"âœ… ë¬¸ì„œ ìˆ˜ì§‘ ì™„ë£Œ: {success_count}/{total_chunks} ì²­í¬ ì„±ê³µ")
            else:
                print(f"âŒ ë¬¸ì„œ ìˆ˜ì§‘ ì‹¤íŒ¨: ëª¨ë“  ì²­í¬ ì¶”ê°€ ì‹¤íŒ¨")

            return result

        except Exception as e:
            print(f"âŒ ë¬¸ì„œ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": str(e),
                "file_path": file_path,
                "ingestion_time": datetime.now().isoformat()
            }

    async def ingest_directory(
        self,
        directory_path: str,
        agent_type: str = "auto",
        recursive: bool = True,
        file_patterns: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  ì§€ì› íŒŒì¼ì„ RAG ì‹œìŠ¤í…œì— ìˆ˜ì§‘í•©ë‹ˆë‹¤.
        """
        try:
            directory = Path(directory_path)
            if not directory.exists():
                raise FileNotFoundError(f"ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {directory_path}")

            print(f"ğŸ“ ë””ë ‰í† ë¦¬ ìˆ˜ì§‘ ì‹œì‘: {directory_path}")

            # ì§€ì› íŒŒì¼ ì°¾ê¸°
            files = self._find_supported_files(directory, recursive, file_patterns)

            if not files:
                print("âš ï¸ ì§€ì›í•˜ëŠ” ë¬¸ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return {
                    "success": False,
                    "message": "ì§€ì›í•˜ëŠ” ë¬¸ì„œ íŒŒì¼ ì—†ìŒ",
                    "total_files": 0
                }

            print(f"ğŸ“„ {len(files)}ê°œ íŒŒì¼ ë°œê²¬")

            # ê° íŒŒì¼ ì²˜ë¦¬
            results = []
            success_count = 0

            for file_path in files:
                print(f"\nì²˜ë¦¬ ì¤‘: {file_path.name}")
                result = await self.ingest_single_document(
                    str(file_path),
                    agent_type,
                    source_name=f"directory_{file_path.stem}"
                )
                results.append(result)

                if result["success"]:
                    success_count += 1

            # ì „ì²´ ê²°ê³¼ ìš”ì•½
            summary = {
                "success": success_count > 0,
                "directory_path": directory_path,
                "total_files": len(files),
                "success_files": success_count,
                "failed_files": len(files) - success_count,
                "file_results": results,
                "ingestion_time": datetime.now().isoformat()
            }

            print(f"\nğŸ“Š ë””ë ‰í† ë¦¬ ìˆ˜ì§‘ ì™„ë£Œ: {success_count}/{len(files)} íŒŒì¼ ì„±ê³µ")
            return summary

        except Exception as e:
            print(f"âŒ ë””ë ‰í† ë¦¬ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                "success": False,
                "error": str(e),
                "directory_path": directory_path,
                "ingestion_time": datetime.now().isoformat()
            }

    async def ingest_batch_files(
        self,
        file_paths: List[str],
        agent_type: str = "auto",
        source_prefix: str = "batch"
    ) -> Dict[str, Any]:
        """
        ì—¬ëŸ¬ íŒŒì¼ì„ ë°°ì¹˜ë¡œ RAG ì‹œìŠ¤í…œì— ìˆ˜ì§‘í•©ë‹ˆë‹¤.
        """
        print(f"ğŸ“¦ ë°°ì¹˜ ìˆ˜ì§‘ ì‹œì‘: {len(file_paths)}ê°œ íŒŒì¼")

        results = []
        success_count = 0

        for i, file_path in enumerate(file_paths):
            print(f"\n[{i+1}/{len(file_paths)}] ì²˜ë¦¬ ì¤‘: {Path(file_path).name}")

            result = await self.ingest_single_document(
                file_path,
                agent_type,
                source_name=f"{source_prefix}_{Path(file_path).stem}"
            )
            results.append(result)

            if result["success"]:
                success_count += 1

        summary = {
            "success": success_count > 0,
            "total_files": len(file_paths),
            "success_files": success_count,
            "failed_files": len(file_paths) - success_count,
            "file_results": results,
            "ingestion_time": datetime.now().isoformat()
        }

        print(f"\nğŸ“Š ë°°ì¹˜ ìˆ˜ì§‘ ì™„ë£Œ: {success_count}/{len(file_paths)} íŒŒì¼ ì„±ê³µ")
        return summary

    async def ingest_agent_directories(
        self,
        documents_root: str = "data/documents",
        recursive: bool = True
    ) -> Dict[str, Any]:
        """
        ì—ì´ì „íŠ¸ë³„ ë””ë ‰í† ë¦¬ êµ¬ì¡°ì—ì„œ ëª¨ë“  ë¬¸ì„œë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
        documents_root/source_code/, documents_root/binary/ ë“±ì˜ êµ¬ì¡°ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        """
        print(f"ğŸ—‚ï¸ ì—ì´ì „íŠ¸ë³„ ë””ë ‰í† ë¦¬ ìˆ˜ì§‘ ì‹œì‘: {documents_root}")

        documents_path = Path(documents_root)
        if not documents_path.exists():
            raise FileNotFoundError(f"ë¬¸ì„œ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {documents_root}")

        overall_results = {
            "success": False,
            "documents_root": documents_root,
            "agent_results": {},
            "total_files": 0,
            "total_success": 0,
            "total_failed": 0,
            "ingestion_time": datetime.now().isoformat()
        }

        total_success = 0
        total_files = 0

        for agent_type in self.supported_agents:
            agent_dir = documents_path / agent_type

            if not agent_dir.exists():
                print(f"âš ï¸ {agent_type} ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {agent_dir}")
                overall_results["agent_results"][agent_type] = {
                    "success": False,
                    "message": "ë””ë ‰í† ë¦¬ ì—†ìŒ",
                    "total_files": 0
                }
                continue

            print(f"\nğŸ“ {agent_type} ë””ë ‰í† ë¦¬ ì²˜ë¦¬ ì¤‘...")

            # í•´ë‹¹ ì—ì´ì „íŠ¸ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  íŒŒì¼ ìˆ˜ì§‘
            agent_result = await self.ingest_directory(
                str(agent_dir),
                agent_type=agent_type,  # ì—ì´ì „íŠ¸ íƒ€ì… ëª…ì‹œì  ì§€ì •
                recursive=recursive
            )

            overall_results["agent_results"][agent_type] = agent_result

            if agent_result["success"]:
                total_success += agent_result["success_files"]
            total_files += agent_result["total_files"]

        overall_results["total_files"] = total_files
        overall_results["total_success"] = total_success
        overall_results["total_failed"] = total_files - total_success
        overall_results["success"] = total_success > 0

        print(f"\nğŸ¯ ì „ì²´ ì—ì´ì „íŠ¸ë³„ ìˆ˜ì§‘ ì™„ë£Œ:")
        print(f"  ì´ íŒŒì¼: {total_files}")
        print(f"  ì„±ê³µ: {total_success}")
        print(f"  ì‹¤íŒ¨: {total_files - total_success}")

        for agent_type, result in overall_results["agent_results"].items():
            if result.get("total_files", 0) > 0:
                print(f"  {agent_type}: {result.get('success_files', 0)}/{result.get('total_files', 0)} ì„±ê³µ")

        return overall_results

    def _find_supported_files(
        self,
        directory: Path,
        recursive: bool,
        file_patterns: Optional[List[str]]
    ) -> List[Path]:
        """ì§€ì›í•˜ëŠ” íŒŒì¼ë“¤ì„ ì°¾ìŠµë‹ˆë‹¤."""
        files = []

        # ê²€ìƒ‰ íŒ¨í„´ ì„¤ì •
        if recursive:
            search_pattern = "**/*"
        else:
            search_pattern = "*"

        # ëª¨ë“  íŒŒì¼ ì°¾ê¸°
        for file_path in directory.glob(search_pattern):
            if file_path.is_file() and self.processor.is_supported(str(file_path)):
                # íŒ¨í„´ í•„í„°ë§
                if file_patterns:
                    if any(pattern in file_path.name for pattern in file_patterns):
                        files.append(file_path)
                else:
                    files.append(file_path)

        return files

    def _create_chunk_metadata(
        self,
        chunk: Dict[str, Any],
        file_info: Dict[str, Any],
        source_name: str,
        confidence: float
    ) -> Dict[str, Any]:
        """ì²­í¬ ë©”íƒ€ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        return {
            "chunk_index": chunk["index"],
            "chunk_hash": chunk["chunk_hash"],
            "char_count": chunk["char_count"],
            "word_count": chunk["word_count"],
            "source_file": file_info["filename"],
            "file_size": file_info["file_size"],
            "file_hash": file_info["file_hash"],
            "source_name": source_name,
            "confidence": confidence,
            "ingestion_time": datetime.now().isoformat()
        }

    async def validate_ingestion(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """ìˆ˜ì§‘ ê²°ê³¼ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤."""
        if not result.get("success"):
            return {"valid": False, "reason": "ìˆ˜ì§‘ ì‹¤íŒ¨"}

        agent_type = result.get("agent_type")
        source_name = result.get("source_name")

        if not agent_type or not source_name:
            return {"valid": False, "reason": "í•„ìˆ˜ ì •ë³´ ëˆ„ë½"}

        try:
            # ì§€ì‹ ë§¤ë‹ˆì €ì—ì„œ ì‹¤ì œë¡œ ê²€ìƒ‰í•´ë³´ê¸°
            knowledge_manager = await KnowledgeManagerFactory.get_manager(agent_type)
            search_result = await knowledge_manager.search_relevant_context(
                query=source_name,
                top_k=1
            )

            if search_result.get("contexts"):
                return {
                    "valid": True,
                    "found_chunks": len(search_result["contexts"]),
                    "avg_confidence": search_result.get("confidence", 0)
                }
            else:
                return {"valid": False, "reason": "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"}

        except Exception as e:
            return {"valid": False, "reason": f"ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}"}

# ì˜ì¡´ì„± ì£¼ì…ì„ ìœ„í•œ í•¨ìˆ˜
def get_document_ingestion_pipeline():
    return DocumentIngestionPipeline()